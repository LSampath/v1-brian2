{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.cm as cmap\n",
    "import time\n",
    "import os.path\n",
    "import scipy\n",
    "import pickle as pickle\n",
    "from struct import unpack\n",
    "from brian2 import *\n",
    "import brian2 as b2\n",
    "from brian2tools import *\n",
    "\n",
    "# specify the location of the MNIST data\n",
    "MNIST_data_path = ''\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# functions\n",
    "#------------------------------------------------------------------------------\n",
    "def get_labeled_data(picklename, bTrain = True):\n",
    "    \"\"\"Read input-vector (image) and target class (label, 0-9) and return\n",
    "       it as list of tuples.\n",
    "    \"\"\"\n",
    "    if os.path.isfile('%s.pickle' % picklename):\n",
    "        data = pickle.load(open('%s.pickle' % picklename, \"rb\"))\n",
    "    else:\n",
    "        # Open the images with gzip in read binary mode\n",
    "        if bTrain:\n",
    "            images = open(MNIST_data_path + 'train-images.idx3-ubyte','rb')\n",
    "            labels = open(MNIST_data_path + 'train-labels.idx1-ubyte','rb')\n",
    "        else:\n",
    "            images = open(MNIST_data_path + 't10k-images.idx3-ubyte','rb')\n",
    "            labels = open(MNIST_data_path + 't10k-labels.idx1-ubyte','rb')\n",
    "        # Get metadata for images\n",
    "        images.read(4)  # skip the magic_number\n",
    "        number_of_images = unpack('>I', images.read(4))[0]\n",
    "        rows = unpack('>I', images.read(4))[0]\n",
    "        cols = unpack('>I', images.read(4))[0]\n",
    "        # Get metadata for labels\n",
    "        labels.read(4)  # skip the magic_number\n",
    "        N = unpack('>I', labels.read(4))[0]\n",
    "\n",
    "        if number_of_images != N:\n",
    "            raise Exception('number of labels did not match the number of images')\n",
    "        # Get the data\n",
    "        x = np.zeros((N, rows, cols), dtype=np.uint8)  # Initialize numpy array\n",
    "        y = np.zeros((N, 1), dtype=np.uint8)  # Initialize numpy array\n",
    "        for i in range(N):\n",
    "            if i % 1000 == 0:\n",
    "                print(\"i: %i\" % i)\n",
    "            x[i] = [[unpack('>B', images.read(1))[0] for unused_col in range(cols)]  for unused_row in range(rows) ]\n",
    "            y[i] = unpack('>B', labels.read(1))[0]\n",
    "\n",
    "        data = {'x': x, 'y': y, 'rows': rows, 'cols': cols}\n",
    "        pickle.dump(data, open(\"%s.pickle\" % picklename, \"wb\"))\n",
    "    return data\n",
    "\n",
    "def get_matrix_from_file(fileName):\n",
    "    offset = len(ending) + 4\n",
    "    if fileName[-4-offset] == 'X':\n",
    "        n_src = n_input\n",
    "    else:\n",
    "        if fileName[-3-offset]=='e':\n",
    "            n_src = n_e\n",
    "        else:\n",
    "            n_src = n_i\n",
    "    if fileName[-1-offset]=='e':\n",
    "        n_tgt = n_e\n",
    "    else:\n",
    "        n_tgt = n_i\n",
    "    readout = np.load(fileName)\n",
    "    print(readout.shape, fileName)\n",
    "    value_arr = np.zeros((n_src, n_tgt))\n",
    "    if not readout.shape == (0,):\n",
    "        value_arr[np.int32(readout[:,0]), np.int32(readout[:,1])] = readout[:,2]\n",
    "    return value_arr\n",
    "\n",
    "\n",
    "def save_connections(ending = ''):\n",
    "    print('save connections')\n",
    "    for connName in save_conns:\n",
    "        conn = connections[connName]\n",
    "        connListSparse = zip(conn.i, conn.j, conn.w)\n",
    "        np.save(data_path + 'weights/' + connName + ending, connListSparse)\n",
    "\n",
    "def save_theta(ending = ''):\n",
    "    print('save theta')\n",
    "    for pop_name in population_names:\n",
    "        np.save(data_path + 'weights/theta_' + pop_name + ending, neuron_groups[pop_name + 'e'].theta)\n",
    "\n",
    "def normalize_weights():\n",
    "    for connName in connections:\n",
    "        if connName[1] == 'e' and connName[3] == 'e':\n",
    "            len_source = len(connections[connName].source)\n",
    "            len_target = len(connections[connName].target)\n",
    "            connection = np.zeros((len_source, len_target))\n",
    "            connection[connections[connName].i, connections[connName].j] = connections[connName].w\n",
    "            temp_conn = np.copy(connection)\n",
    "            colSums = np.sum(temp_conn, axis = 0)\n",
    "            colFactors = weight['ee_input']/colSums\n",
    "            for j in range(n_e):#\n",
    "                temp_conn[:,j] *= colFactors[j]\n",
    "            connections[connName].w = temp_conn[connections[connName].i, connections[connName].j]\n",
    "\n",
    "def get_2d_input_weights():\n",
    "    name = 'XeAe'\n",
    "    weight_matrix = np.zeros((n_input, n_e))\n",
    "    n_e_sqrt = int(np.sqrt(n_e))\n",
    "    n_in_sqrt = int(np.sqrt(n_input))\n",
    "    num_values_col = n_e_sqrt*n_in_sqrt\n",
    "    num_values_row = num_values_col\n",
    "    rearranged_weights = np.zeros((num_values_col, num_values_row))\n",
    "    connMatrix = np.zeros((n_input, n_e))\n",
    "    connMatrix[connections[name].i, connections[name].j] = connections[name].w\n",
    "    weight_matrix = np.copy(connMatrix)\n",
    "\n",
    "    for i in range(n_e_sqrt):\n",
    "        for j in range(n_e_sqrt):\n",
    "                rearranged_weights[i*n_in_sqrt : (i+1)*n_in_sqrt, j*n_in_sqrt : (j+1)*n_in_sqrt] = \\\n",
    "                    weight_matrix[:, i + j*n_e_sqrt].reshape((n_in_sqrt, n_in_sqrt))\n",
    "    return rearranged_weights\n",
    "\n",
    "\n",
    "def plot_2d_input_weights():\n",
    "    name = 'XeAe'\n",
    "    weights = get_2d_input_weights()\n",
    "    fig = b2.figure(fig_num, figsize = (18, 18))\n",
    "    im2 = b2.imshow(weights, interpolation = \"nearest\", vmin = 0, vmax = wmax_ee, cmap = cmap.get_cmap('hot_r'))\n",
    "    b2.colorbar(im2)\n",
    "    b2.title('weights of connection' + name)\n",
    "    fig.canvas.draw()\n",
    "    return im2, fig\n",
    "\n",
    "def update_2d_input_weights(im, fig):\n",
    "    weights = get_2d_input_weights()\n",
    "    im.set_array(weights)\n",
    "    fig.canvas.draw()\n",
    "    return im\n",
    "\n",
    "def get_current_performance(performance, current_example_num):\n",
    "    current_evaluation = int(current_example_num/update_interval)\n",
    "    start_num = current_example_num - update_interval\n",
    "    end_num = current_example_num\n",
    "    difference = outputNumbers[start_num:end_num, 0] - input_numbers[start_num:end_num]\n",
    "    correct = len(np.where(difference == 0)[0])\n",
    "    performance[current_evaluation] = correct / float(update_interval) * 100\n",
    "    return performance\n",
    "\n",
    "def plot_performance(fig_num):\n",
    "    num_evaluations = int(num_examples/update_interval)\n",
    "    time_steps = range(0, num_evaluations)\n",
    "    performance = np.zeros(num_evaluations)\n",
    "    fig = b2.figure(fig_num, figsize = (5, 5))\n",
    "    fig_num += 1\n",
    "    ax = fig.add_subplot(111)\n",
    "    im2, = ax.plot(time_steps, performance) #my_cmap\n",
    "    b2.ylim(ymax = 100)\n",
    "    b2.title('Classification performance')\n",
    "    fig.canvas.draw()\n",
    "    return im2, performance, fig_num, fig\n",
    "\n",
    "def update_performance_plot(im, performance, current_example_num, fig):\n",
    "    performance = get_current_performance(performance, current_example_num)\n",
    "    im.set_ydata(performance)\n",
    "    fig.canvas.draw()\n",
    "    return im, performance\n",
    "\n",
    "def get_recognized_number_ranking(assignments, spike_rates):\n",
    "    summed_rates = [0] * 10\n",
    "    num_assignments = [0] * 10\n",
    "    for i in range(10):\n",
    "        num_assignments[i] = len(np.where(assignments == i)[0])\n",
    "        if num_assignments[i] > 0:\n",
    "            summed_rates[i] = np.sum(spike_rates[assignments == i]) / num_assignments[i]\n",
    "    return np.argsort(summed_rates)[::-1]\n",
    "\n",
    "def get_new_assignments(result_monitor, input_numbers):\n",
    "    assignments = np.zeros(n_e)\n",
    "    input_nums = np.asarray(input_numbers)\n",
    "    maximum_rate = [0] * n_e\n",
    "    for j in range(10):\n",
    "        num_assignments = len(np.where(input_nums == j)[0])\n",
    "        if num_assignments > 0:\n",
    "            rate = np.sum(result_monitor[input_nums == j], axis = 0) / num_assignments\n",
    "        for i in range(n_e):\n",
    "            if rate[i] > maximum_rate[i]:\n",
    "                maximum_rate[i] = rate[i]\n",
    "                assignments[i] = j\n",
    "    return assignments\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# load MNIST\n",
    "#------------------------------------------------------------------------------\n",
    "start = time.time()\n",
    "training = get_labeled_data(MNIST_data_path + 'training')\n",
    "end = time.time()\n",
    "print('time needed to load training set:', end - start)\n",
    "\n",
    "start = time.time()\n",
    "testing = get_labeled_data(MNIST_data_path + 'testing', bTrain = False)\n",
    "end = time.time()\n",
    "print('time needed to load test set:', end - start)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# set parameters and equations\n",
    "#------------------------------------------------------------------------------\n",
    "test_mode = False\n",
    "\n",
    "np.random.seed(0)\n",
    "data_path = './'\n",
    "if test_mode:\n",
    "    weight_path = data_path + 'weights/'\n",
    "    num_examples = 10000 * 1\n",
    "    use_testing_set = True\n",
    "    do_plot_performance = False\n",
    "    record_spikes = True\n",
    "    ee_STDP_on = False\n",
    "    update_interval = num_examples\n",
    "else:\n",
    "    weight_path = data_path + 'random/'\n",
    "    num_examples = 60000 * 3\n",
    "    use_testing_set = False\n",
    "    do_plot_performance = True\n",
    "    if num_examples <= 60000:\n",
    "        record_spikes = True\n",
    "    else:\n",
    "        record_spikes = True\n",
    "    ee_STDP_on = True\n",
    "\n",
    "\n",
    "ending = ''\n",
    "n_input = 784\n",
    "n_e = 400\n",
    "n_i = n_e\n",
    "single_example_time =   0.35 * b2.second #\n",
    "resting_time = 0.15 * b2.second\n",
    "runtime = num_examples * (single_example_time + resting_time)\n",
    "if num_examples <= 10000:\n",
    "    update_interval = num_examples\n",
    "    weight_update_interval = 20\n",
    "else:\n",
    "    update_interval = 10000\n",
    "    weight_update_interval = 100\n",
    "if num_examples <= 60000:\n",
    "    save_connections_interval = 10000\n",
    "else:\n",
    "    save_connections_interval = 10000\n",
    "    update_interval = 10000\n",
    "\n",
    "v_rest_e = -65. * b2.mV\n",
    "v_rest_i = -60. * b2.mV\n",
    "v_reset_e = -65. * b2.mV\n",
    "v_reset_i = -45. * b2.mV\n",
    "v_thresh_e = -52. * b2.mV\n",
    "v_thresh_i = -40. * b2.mV\n",
    "refrac_e = 5. * b2.ms\n",
    "refrac_i = 2. * b2.ms\n",
    "\n",
    "weight = {}\n",
    "delay = {}\n",
    "input_population_names = ['X']\n",
    "population_names = ['A']\n",
    "input_connection_names = ['XA']\n",
    "save_conns = ['XeAe']\n",
    "input_conn_names = ['ee_input']\n",
    "recurrent_conn_names = ['ei', 'ie']\n",
    "weight['ee_input'] = 78.\n",
    "delay['ee_input'] = (0*b2.ms,10*b2.ms)\n",
    "delay['ei_input'] = (0*b2.ms,5*b2.ms)\n",
    "input_intensity = 2.\n",
    "start_input_intensity = input_intensity\n",
    "\n",
    "tc_pre_ee = 20*b2.ms\n",
    "tc_post_1_ee = 20*b2.ms\n",
    "tc_post_2_ee = 40*b2.ms\n",
    "nu_ee_pre =  0.0001      # learning rate\n",
    "nu_ee_post = 0.01       # learning rate\n",
    "wmax_ee = 1.0\n",
    "exp_ee_pre = 0.2\n",
    "exp_ee_post = exp_ee_pre\n",
    "STDP_offset = 0.4\n",
    "\n",
    "if test_mode:\n",
    "    scr_e = 'v = v_reset_e; timer = 0*ms'\n",
    "else:\n",
    "    tc_theta = 1e7 * b2.ms\n",
    "    theta_plus_e = 0.05 * b2.mV\n",
    "    scr_e = 'v = v_reset_e; theta += theta_plus_e; timer = 0*ms'\n",
    "offset = 20.0*b2.mV\n",
    "v_thresh_e_str = '(v>(theta -  + v_thresh_e)) and (timer>refrac_e)'\n",
    "v_thresh_i_str = 'v>v_thresh_i'\n",
    "v_reset_i_str = 'v=v_reset_i'\n",
    "\n",
    "\n",
    "neuron_eqs_e = '''\n",
    "        dv/dt = ((v_rest_e - v) + (I_synE+I_synI) / nS) / (100*ms)  : volt (unless refractory)\n",
    "        I_synE = ge * nS *         -v                           : amp\n",
    "        I_synI = gi * nS * (-100.*mV-v)                          : amp\n",
    "        dge/dt = -ge/(1.0*ms)                                   : 1\n",
    "        dgi/dt = -gi/(2.0*ms)                                  : 1\n",
    "        '''\n",
    "if test_mode:\n",
    "    neuron_eqs_e += '\\n  theta      :volt'\n",
    "else:\n",
    "    neuron_eqs_e += '\\n  dtheta/dt = -theta / (tc_theta)  : volt'\n",
    "neuron_eqs_e += '\\n  dtimer/dt = 0.1  : second'\n",
    "\n",
    "neuron_eqs_i = '''\n",
    "        dv/dt = ((v_rest_i - v) + (I_synE+I_synI) / nS) / (10*ms)  : volt (unless refractory)\n",
    "        I_synE = ge * nS *         -v                           : amp\n",
    "        I_synI = gi * nS * (-85.*mV-v)                          : amp\n",
    "        dge/dt = -ge/(1.0*ms)                                   : 1\n",
    "        dgi/dt = -gi/(2.0*ms)                                  : 1\n",
    "        '''\n",
    "eqs_stdp_ee = '''\n",
    "                post2before                            : 1\n",
    "                dpre/dt   =   -pre/(tc_pre_ee)         : 1 (event-driven)\n",
    "                dpost1/dt  = -post1/(tc_post_1_ee)     : 1 (event-driven)\n",
    "                dpost2/dt  = -post2/(tc_post_2_ee)     : 1 (event-driven)\n",
    "            '''\n",
    "eqs_stdp_pre_ee = 'pre = 1.; w = clip(w + nu_ee_pre * post1, 0, wmax_ee)'\n",
    "eqs_stdp_post_ee = 'post2before = post2; w = clip(w + nu_ee_post * pre * post2before, 0, wmax_ee); post1 = 1.; post2 = 1.'\n",
    "\n",
    "b2.ion()\n",
    "fig_num = 1\n",
    "neuron_groups = {}\n",
    "input_groups = {}\n",
    "connections = {}\n",
    "rate_monitors = {}\n",
    "spike_monitors = {}\n",
    "spike_counters = {}\n",
    "result_monitor = np.zeros((update_interval,n_e))\n",
    "\n",
    "neuron_groups['e'] = b2.NeuronGroup(n_e*len(population_names), neuron_eqs_e, threshold= v_thresh_e_str, refractory= refrac_e, reset= scr_e, method='euler')\n",
    "neuron_groups['i'] = b2.NeuronGroup(n_i*len(population_names), neuron_eqs_i, threshold= v_thresh_i_str, refractory= refrac_i, reset= v_reset_i_str, method='euler')\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# create network population and recurrent connections\n",
    "#------------------------------------------------------------------------------\n",
    "for subgroup_n, name in enumerate(population_names):\n",
    "    print('create neuron group', name)\n",
    "\n",
    "    neuron_groups[name+'e'] = neuron_groups['e'][subgroup_n*n_e:(subgroup_n+1)*n_e]\n",
    "    neuron_groups[name+'i'] = neuron_groups['i'][subgroup_n*n_i:(subgroup_n+1)*n_e]\n",
    "\n",
    "    neuron_groups[name+'e'].v = v_rest_e - 40. * b2.mV\n",
    "    neuron_groups[name+'i'].v = v_rest_i - 40. * b2.mV\n",
    "    if test_mode or weight_path[-8:] == 'weights/':\n",
    "        neuron_groups['e'].theta = np.load(weight_path + 'theta_' + name + ending + '.npy') * b2.volt\n",
    "    else:\n",
    "        neuron_groups['e'].theta = np.ones((n_e)) * 20.0*b2.mV\n",
    "\n",
    "    print('create recurrent connections')\n",
    "    for conn_type in recurrent_conn_names:\n",
    "        connName = name+conn_type[0]+name+conn_type[1]\n",
    "        weightMatrix = get_matrix_from_file(weight_path + '../random/' + connName + ending + '.npy')\n",
    "        model = 'w : 1'\n",
    "        pre = 'g%s_post += w' % conn_type[0]\n",
    "        post = ''\n",
    "        if ee_STDP_on:\n",
    "            if 'ee' in recurrent_conn_names:\n",
    "                model += eqs_stdp_ee\n",
    "                pre += '; ' + eqs_stdp_pre_ee\n",
    "                post = eqs_stdp_post_ee\n",
    "        connections[connName] = b2.Synapses(neuron_groups[connName[0:2]], neuron_groups[connName[2:4]],\n",
    "                                                    model=model, on_pre=pre, on_post=post)\n",
    "        connections[connName].connect(True) # all-to-all connection\n",
    "        connections[connName].w = weightMatrix[connections[connName].i, connections[connName].j]\n",
    "\n",
    "    print('create monitors for', name)\n",
    "    rate_monitors[name+'e'] = b2.PopulationRateMonitor(neuron_groups[name+'e'])\n",
    "    rate_monitors[name+'i'] = b2.PopulationRateMonitor(neuron_groups[name+'i'])\n",
    "    spike_counters[name+'e'] = b2.SpikeMonitor(neuron_groups[name+'e'])\n",
    "\n",
    "    if record_spikes:\n",
    "        spike_monitors[name+'e'] = b2.SpikeMonitor(neuron_groups[name+'e'])\n",
    "        spike_monitors[name+'i'] = b2.SpikeMonitor(neuron_groups[name+'i'])\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# create input population and connections from input populations\n",
    "#------------------------------------------------------------------------------\n",
    "pop_values = [0,0,0]\n",
    "for i,name in enumerate(input_population_names):\n",
    "    input_groups[name+'e'] = b2.PoissonGroup(n_input, 0*Hz)\n",
    "    rate_monitors[name+'e'] = b2.PopulationRateMonitor(input_groups[name+'e'])\n",
    "\n",
    "for name in input_connection_names:\n",
    "    print('create connections between', name[0], 'and', name[1])\n",
    "    for connType in input_conn_names:\n",
    "        connName = name[0] + connType[0] + name[1] + connType[1]\n",
    "        weightMatrix = get_matrix_from_file(weight_path + connName + ending + '.npy')\n",
    "        model = 'w : 1'\n",
    "        pre = 'g%s_post += w' % connType[0]\n",
    "        post = ''\n",
    "        if ee_STDP_on:\n",
    "            print('create STDP for connection', name[0]+'e'+name[1]+'e')\n",
    "            model += eqs_stdp_ee\n",
    "            pre += '; ' + eqs_stdp_pre_ee\n",
    "            post = eqs_stdp_post_ee\n",
    "\n",
    "        connections[connName] = b2.Synapses(input_groups[connName[0:2]], neuron_groups[connName[2:4]],\n",
    "                                                    model=model, on_pre=pre, on_post=post)\n",
    "        minDelay = delay[connType][0]\n",
    "        maxDelay = delay[connType][1]\n",
    "        deltaDelay = maxDelay - minDelay\n",
    "        # TODO: test this\n",
    "        connections[connName].connect(True) # all-to-all connection\n",
    "        connections[connName].delay = 'minDelay + rand() * deltaDelay'\n",
    "        connections[connName].w = weightMatrix[connections[connName].i, connections[connName].j]\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# run the simulation and set inputs\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "net = Network()\n",
    "for obj_list in [neuron_groups, input_groups, connections, rate_monitors,\n",
    "        spike_monitors, spike_counters]:\n",
    "    for key in obj_list:\n",
    "        net.add(obj_list[key])\n",
    "\n",
    "previous_spike_count = np.zeros(n_e)\n",
    "assignments = np.zeros(n_e)\n",
    "input_numbers = [0] * num_examples\n",
    "outputNumbers = np.zeros((num_examples, 10))\n",
    "if not test_mode:\n",
    "    input_weight_monitor, fig_weights = plot_2d_input_weights()\n",
    "    fig_num += 1\n",
    "if do_plot_performance:\n",
    "    performance_monitor, performance, fig_num, fig_performance = plot_performance(fig_num)\n",
    "for i,name in enumerate(input_population_names):\n",
    "    input_groups[name+'e'].rates = 0 * Hz\n",
    "net.run(0*second)\n",
    "j = 0\n",
    "while j < (int(num_examples)):\n",
    "    if test_mode:\n",
    "        if use_testing_set:\n",
    "            spike_rates = testing['x'][j%10000,:,:].reshape((n_input)) / 8. *  input_intensity\n",
    "        else:\n",
    "            spike_rates = training['x'][j%60000,:,:].reshape((n_input)) / 8. *  input_intensity\n",
    "    else:\n",
    "        normalize_weights()\n",
    "        spike_rates = training['x'][j%60000,:,:].reshape((n_input)) / 8. *  input_intensity\n",
    "    input_groups['Xe'].rates = spike_rates * Hz\n",
    "#     print 'run number:', j+1, 'of', int(num_examples)\n",
    "    net.run(single_example_time, report='text')\n",
    "\n",
    "    if j % update_interval == 0 and j > 0:\n",
    "        assignments = get_new_assignments(result_monitor[:], input_numbers[j-update_interval : j])\n",
    "    if j % weight_update_interval == 0 and not test_mode:\n",
    "        update_2d_input_weights(input_weight_monitor, fig_weights)\n",
    "    if j % save_connections_interval == 0 and j > 0 and not test_mode:\n",
    "        save_connections(str(j))\n",
    "        save_theta(str(j))\n",
    "\n",
    "    current_spike_count = np.asarray(spike_counters['Ae'].count[:]) - previous_spike_count\n",
    "    previous_spike_count = np.copy(spike_counters['Ae'].count[:])\n",
    "    if np.sum(current_spike_count) < 5:\n",
    "        input_intensity += 1\n",
    "        for i,name in enumerate(input_population_names):\n",
    "            input_groups[name+'e'].rates = 0 * Hz\n",
    "        net.run(resting_time)\n",
    "    else:\n",
    "        result_monitor[j%update_interval,:] = current_spike_count\n",
    "        if test_mode and use_testing_set:\n",
    "            input_numbers[j] = testing['y'][j%10000][0]\n",
    "        else:\n",
    "            input_numbers[j] = training['y'][j%60000][0]\n",
    "        outputNumbers[j,:] = get_recognized_number_ranking(assignments, result_monitor[j%update_interval,:])\n",
    "        if j % 100 == 0 and j > 0:\n",
    "            print('runs done:', j, 'of', int(num_examples))\n",
    "        if j % update_interval == 0 and j > 0:\n",
    "            if do_plot_performance:\n",
    "                unused, performance = update_performance_plot(performance_monitor, performance, j, fig_performance)\n",
    "                print('Classification performance', performance[:(j/float(update_interval))+1])\n",
    "        for i,name in enumerate(input_population_names):\n",
    "            input_groups[name+'e'].rates = 0 * Hz\n",
    "        net.run(resting_time)\n",
    "        input_intensity = start_input_intensity\n",
    "        j += 1\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# save results\n",
    "#------------------------------------------------------------------------------\n",
    "print('save results')\n",
    "if not test_mode:\n",
    "    save_theta()\n",
    "if not test_mode:\n",
    "    save_connections()\n",
    "else:\n",
    "    np.save(data_path + 'activity/resultPopVecs' + str(num_examples), result_monitor)\n",
    "    np.save(data_path + 'activity/inputNumbers' + str(num_examples), input_numbers)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# plot results\n",
    "#------------------------------------------------------------------------------\n",
    "if rate_monitors:\n",
    "    b2.figure(fig_num)\n",
    "    fig_num += 1\n",
    "    for i, name in enumerate(rate_monitors):\n",
    "        b2.subplot(len(rate_monitors), 1, 1+i)\n",
    "        b2.plot(rate_monitors[name].t/b2.second, rate_monitors[name].rate, '.')\n",
    "        b2.title('Rates of population ' + name)\n",
    "\n",
    "if spike_monitors:\n",
    "    b2.figure(fig_num)\n",
    "    fig_num += 1\n",
    "    for i, name in enumerate(spike_monitors):\n",
    "        b2.subplot(len(spike_monitors), 1, 1+i)\n",
    "        b2.plot(spike_monitors[name].t/b2.ms, spike_monitors[name].i, '.')\n",
    "        b2.title('Spikes of population ' + name)\n",
    "\n",
    "if spike_counters:\n",
    "    b2.figure(fig_num)\n",
    "    fig_num += 1\n",
    "    b2.plot(spike_monitors['Ae'].count[:])\n",
    "    b2.title('Spike count of population Ae')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_2d_input_weights()\n",
    "\n",
    "plt.figure(5)\n",
    "\n",
    "subplot(3,1,1)\n",
    "\n",
    "brian_plot(connections['XeAe'].w)\n",
    "subplot(3,1,2)\n",
    "\n",
    "brian_plot(connections['AeAi'].w)\n",
    "\n",
    "subplot(3,1,3)\n",
    "\n",
    "brian_plot(connections['AiAe'].w)\n",
    "\n",
    "\n",
    "plt.figure(6)\n",
    "\n",
    "subplot(3,1,1)\n",
    "\n",
    "brian_plot(connections['XeAe'].delay)\n",
    "subplot(3,1,2)\n",
    "\n",
    "brian_plot(connections['AeAi'].delay)\n",
    "\n",
    "subplot(3,1,3)\n",
    "\n",
    "brian_plot(connections['AiAe'].delay)\n",
    "\n",
    "\n",
    "b2.ioff()\n",
    "b2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SNN simulator",
   "language": "python",
   "name": "sim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
