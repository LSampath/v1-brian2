{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Created on 15.12.2014\n",
    "@author: Peter U. Diehl\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.cm as cmap\n",
    "import time\n",
    "import os.path\n",
    "import scipy \n",
    "import cPickle as pickle\n",
    "from struct import unpack\n",
    "from brian2 import *\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------ \n",
    "# functions\n",
    "#------------------------------------------------------------------------------     \n",
    "def get_labeled_data(picklename, bTrain = True):\n",
    "    \"\"\"Read input-vector (image) and target class (label, 0-9) and return\n",
    "       it as list of tuples.\n",
    "    \"\"\"\n",
    "    if os.path.isfile('%s.pickle' % picklename):\n",
    "        data = pickle.load(open('%s.pickle' % picklename))\n",
    "    else:\n",
    "        # Open the images with gzip in read binary mode\n",
    "        if bTrain:\n",
    "            images = open(MNIST_data_path + 'train-images.idx3-ubyte','rb')\n",
    "            labels = open(MNIST_data_path + 'train-labels.idx1-ubyte','rb')\n",
    "        else:\n",
    "            images = open(MNIST_data_path + 't10k-images.idx3-ubyte','rb')\n",
    "            labels = open(MNIST_data_path + 't10k-labels.idx1-ubyte','rb')\n",
    "        # Get metadata for images\n",
    "        images.read(4)  # skip the magic_number\n",
    "        number_of_images = unpack('>I', images.read(4))[0]\n",
    "        rows = unpack('>I', images.read(4))[0]\n",
    "        cols = unpack('>I', images.read(4))[0]\n",
    "        # Get metadata for labels\n",
    "        labels.read(4)  # skip the magic_number\n",
    "        N = unpack('>I', labels.read(4))[0]\n",
    "        if number_of_images != N:\n",
    "            raise Exception('number of labels did not match the number of images')\n",
    "        # Get the data\n",
    "        x = np.zeros((N, rows, cols), dtype=np.uint8)  # Initialize numpy array\n",
    "        y = np.zeros((N, 1), dtype=np.uint8)  # Initialize numpy array\n",
    "        for i in xrange(N):\n",
    "            if i % 1000 == 0:\n",
    "                print(\"i: %i\" % i)\n",
    "            x[i] = [[unpack('>B', images.read(1))[0] for unused_col in xrange(cols)]  for unused_row in xrange(rows) ]\n",
    "            y[i] = unpack('>B', labels.read(1))[0]\n",
    "        data = {'x': x, 'y': y, 'rows': rows, 'cols': cols}\n",
    "        pickle.dump(data, open(\"%s.pickle\" % picklename, \"wb\"))\n",
    "    return data\n",
    "\n",
    "def get_recognized_number_ranking(assignments, spike_rates):\n",
    "    summed_rates = [0] * 10\n",
    "    num_assignments = [0] * 10\n",
    "    for i in xrange(10):\n",
    "        num_assignments[i] = len(np.where(assignments == i)[0])\n",
    "        if num_assignments[i] > 0:\n",
    "            summed_rates[i] = np.sum(spike_rates[assignments == i]) / num_assignments[i]\n",
    "    return np.argsort(summed_rates)[::-1]\n",
    "\n",
    "def get_new_assignments(result_monitor, input_numbers):\n",
    "    print(result_monitor.shape)\n",
    "    assignments = np.ones(n_e) * -1 # initialize them as not assigned\n",
    "    input_nums = np.asarray(input_numbers)\n",
    "    maximum_rate = [0] * n_e    \n",
    "    for j in xrange(10):\n",
    "        num_inputs = len(np.where(input_nums == j)[0])\n",
    "        if num_inputs > 0:\n",
    "            rate = np.sum(result_monitor[input_nums == j], axis = 0) / num_inputs\n",
    "        for i in xrange(n_e):\n",
    "            if rate[i] > maximum_rate[i]:\n",
    "                maximum_rate[i] = rate[i]\n",
    "                assignments[i] = j \n",
    "    return assignments\n",
    "\n",
    "MNIST_data_path = './'\n",
    "data_path = './activity/'\n",
    "training_ending = '10000'\n",
    "testing_ending = '10000'\n",
    "start_time_training = 0\n",
    "end_time_training = int(training_ending)\n",
    "start_time_testing = 0\n",
    "end_time_testing = int(testing_ending)\n",
    "\n",
    "n_e = 400\n",
    "n_input = 784\n",
    "ending = ''\n",
    "\n",
    "print('load MNIST')\n",
    "training = get_labeled_data(MNIST_data_path + 'training')\n",
    "testing = get_labeled_data(MNIST_data_path + 'testing', bTrain = False)\n",
    "\n",
    "print('load results')\n",
    "training_result_monitor = np.load(data_path + 'resultPopVecs' + training_ending + ending + '.npy')\n",
    "training_input_numbers = np.load(data_path + 'inputNumbers' + training_ending + '.npy')\n",
    "testing_result_monitor = np.load(data_path + 'resultPopVecs' + testing_ending + '.npy')\n",
    "testing_input_numbers = np.load(data_path + 'inputNumbers' + testing_ending + '.npy')\n",
    "print(training_result_monitor.shape)\n",
    "\n",
    "print('get assignments')\n",
    "test_results = np.zeros((10, end_time_testing-start_time_testing))\n",
    "test_results_max = np.zeros((10, end_time_testing-start_time_testing))\n",
    "test_results_top = np.zeros((10, end_time_testing-start_time_testing))\n",
    "test_results_fixed = np.zeros((10, end_time_testing-start_time_testing))\n",
    "assignments = get_new_assignments(training_result_monitor[start_time_training:end_time_training], \n",
    "                                  training_input_numbers[start_time_training:end_time_training])\n",
    "print(assignments)\n",
    "counter = 0 \n",
    "num_tests = end_time_testing / 10000\n",
    "sum_accurracy = [0] * num_tests\n",
    "while (counter < num_tests):\n",
    "    end_time = min(end_time_testing, 10000*(counter+1))\n",
    "    start_time = 10000*counter\n",
    "    test_results = np.zeros((10, end_time-start_time))\n",
    "    print('calculate accuracy for sum')\n",
    "    for i in xrange(end_time - start_time):\n",
    "        test_results[:,i] = get_recognized_number_ranking(assignments, \n",
    "                                                          testing_result_monitor[i+start_time,:])\n",
    "    difference = test_results[0,:] - testing_input_numbers[start_time:end_time]\n",
    "    correct = len(np.where(difference == 0)[0])\n",
    "    incorrect = np.where(difference != 0)[0]\n",
    "    sum_accurracy[counter] = correct/float(end_time-start_time) * 100\n",
    "    print('Sum response - accuracy: ', sum_accurracy[counter], ' num incorrect: ', len(incorrect))\n",
    "    counter += 1\n",
    "print('Sum response - accuracy --> mean: ', np.mean(sum_accurracy),  '--> standard deviation: ', np.std(sum_accurracy))\n",
    "\n",
    "\n",
    "show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SNN simulator",
   "language": "python",
   "name": "sim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
